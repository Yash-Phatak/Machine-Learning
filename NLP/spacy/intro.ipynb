{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x2c68286a030>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x2c6847853d0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x2c68462be60>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x2c6848eba10>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x2c6847cb490>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x2c68462bed0>)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nlp model will process the text and save it to a Doc object once called.\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "Let\n",
      "'s\n",
      "go\n",
      "to\n",
      "N.Y.\n",
      "!\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "# doc will contain tokens of the text\n",
    "doc = nlp('\"Let\\'s go to N.Y.!\"')\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named Entities with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nIn a sentence, a word or a group of words indicates names (e.g., Name of location, person, area, country, state, monetary values, and so on). \\nThe primary purpose of a named entity is to identify it.\\nThe named entities can be accessible with ents attributes of Doc object.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "In a sentence, a word or a group of words indicates names (e.g., Name of location, person, area, country, state, monetary values, and so on). \n",
    "The primary purpose of a named entity is to identify it.\n",
    "The named entities can be accessible with ents attributes of Doc object.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yash is an Machine Learning enthusiast and events head of RoboVITics ----------------------------\n",
      "Yash-PERSON-People, including fictional\n",
      "Machine Learning-GPE-Countries, cities, states\n",
      "RoboVITics-NORP-Nationalities or religious or political groups\n"
     ]
    }
   ],
   "source": [
    "# Normal Tokenisation\n",
    "sentence = nlp(\"Yash is an Machine Learning enthusiast and events head of RoboVITics\")\n",
    "for token in sentence:\n",
    "    print(token.text,end=' ')\n",
    "\n",
    "print('----------------------------')\n",
    "\n",
    "# Named entity\n",
    "for ent in sentence.ents:\n",
    "    print(ent.text+'-'+ent.label_+'-'+str(spacy.explain(ent.label_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing named entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    last few years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    USA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " generates \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " revenue</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "doc = nlp('Over last few years USA generates $6 million revenue')\n",
    "displacy.render(doc,style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"06ee2b526c6740fb9b82debb4fd168df-0\" class=\"displacy\" width=\"600\" height=\"302.0\" direction=\"ltr\" style=\"max-width: none; height: 302.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">India</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">beautiful</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">country.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-06ee2b526c6740fb9b82debb4fd168df-0-0\" stroke-width=\"2px\" d=\"M70,167.0 C70,112.0 150.0,112.0 150.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-06ee2b526c6740fb9b82debb4fd168df-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,169.0 L62,157.0 78,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-06ee2b526c6740fb9b82debb4fd168df-0-1\" stroke-width=\"2px\" d=\"M290,167.0 C290,57.0 485.0,57.0 485.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-06ee2b526c6740fb9b82debb4fd168df-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M290,169.0 L282,157.0 298,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-06ee2b526c6740fb9b82debb4fd168df-0-2\" stroke-width=\"2px\" d=\"M400,167.0 C400,112.0 480.0,112.0 480.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-06ee2b526c6740fb9b82debb4fd168df-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400,169.0 L392,157.0 408,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-06ee2b526c6740fb9b82debb4fd168df-0-3\" stroke-width=\"2px\" d=\"M180,167.0 C180,2.0 490.0,2.0 490.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-06ee2b526c6740fb9b82debb4fd168df-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M490.0,169.0 L498.0,157.0 482.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "doc = nlp('India is a beautiful country.')\n",
    "displacy.render(doc,style='dep',jupyter=True,options={'distance':110})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy doesnt have a Stemmer and relies on lemmatization\n",
    "# We prefer PorterStemmer or Snowball Stemmer from nltk for Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization and POS Tagging with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He           PRON   PRON   1655312771067108281    he\n",
      "is           AUX    AUX    10382539506755952630   be\n",
      "a            DET    DET    11901859001352538922   a\n",
      "runner       NOUN   NOUN   12640964157389618806   runner\n",
      "in           ADP    ADP    3002984154512732771    in\n",
      "a            DET    DET    11901859001352538922   a\n",
      "competition  NOUN   NOUN   4661638505416061516    competition\n",
      "because      SCONJ  SCONJ  16950148841647037698   because\n",
      "he           PRON   PRON   1655312771067108281    he\n",
      "loves        VERB   VERB   3702023516439754181    love\n",
      "to           PART   PART   3791531372978436496    to\n",
      "run          VERB   VERB   12767647472892411841   run\n",
      "since        SCONJ  SCONJ  10066841407251338481   since\n",
      "he           PRON   PRON   1655312771067108281    he\n",
      "ran          VERB   VERB   12767647472892411841   run\n",
      "today        NOUN   NOUN   11042482332948150395   today\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"He is a runner in a competition because he loves to run since he ran today\")\n",
    "\n",
    "for token in doc:\n",
    "    print(f'{token.text:{12}} {token.pos_:{6}} {token.pos_:{6}} {token.lemma:<{22}} {token.lemma_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'done', 'why', 'thru', 'enough', 'part', 'yourself', 'themselves', \"'s\", 'former', 'herein', 'in', 'beyond', 'really', 'latter', 'nine', \"'ve\", 'about', 'becoming', 'will', 'whose', 'further', 'get', 'almost', 'hers', 'who', 'third', 'and', 'they', 'indeed', 'name', 'seem', 'such', 'others', 'does', 'latterly', 'anything', 'a', 'go', 'n‘t', 'few', 'thus', 'my', '‘d', 'between', 'along', 'anyway', 'nor', 'keep', \"n't\", 'else', 'must', 'myself', 'all', 'ca', 'same', 'whatever', 'but', 'fifty', 'without', 'during', 'front', 'through', 'every', 'where', 'both', 'various', 'thereafter', 'give', 'yet', '‘s', 'could', 'only', 'otherwise', 'show', 'fifteen', 'whither', 'over', 'other', 'behind', 'for', 'has', \"'ll\", 'against', 'either', 'hereupon', 'off', 'should', 'what', 'is', 'first', 'our', 'somewhere', 'together', 'whenever', 'itself', 'several', '’d', 'those', 'someone', 'many', 'nobody', 'ours', '‘ll', 'being', 'out', 'himself', 'or', 'mine', 'not', '’ll', 'which', 'yourselves', 'hereby', 'so', 'however', 'even', 'serious', 'doing', 'please', 'also', 'everything', 'per', 'across', 'up', 'made', 'moreover', 'formerly', 'take', 'whether', 'this', 'became', 'them', 'under', 're', 'whereupon', 'whoever', '’s', 'top', 'n’t', 'when', 'his', 'say', 'alone', 'would', '‘m', 'down', 'amount', 'anyhow', 'six', '‘re', 'yours', '’ve', 'call', 'two', 'an', 'each', 'although', 'thence', 'were', 'again', 'hence', 'afterwards', \"'d\", '’m', 'meanwhile', 'something', 'she', 'due', 'whereby', 'as', 'him', 'while', 'five', 'last', 'never', 'become', 'into', 'still', 'full', 'four', 'are', 'twenty', 'whereas', 'sixty', 'beside', 'noone', \"'m\", 'three', 'neither', 'here', 'the', 'us', 'among', 'namely', 'some', 'until', 'via', 'anyone', 'own', 'more', 'thereupon', 'therefore', 'by', 'ten', 'back', 'bottom', 'hereafter', 'might', 'less', 'therein', 'thereby', 'everywhere', 'quite', 'herself', 'mostly', 'from', 'her', 'unless', 'throughout', 'though', 'whence', 'had', 'nothing', 'whereafter', 'there', 'to', 'side', '‘ve', 'on', 'before', 'besides', 'ever', 'their', 'within', 'how', 'may', 'eleven', 'since', 'he', 'very', 'sometime', 'nowhere', 'just', 'seems', 'most', 'did', 'any', 'its', 'you', 'next', 'wherever', 'wherein', 'always', 'after', '’re', 'move', 'was', 'one', 'put', 'onto', 'towards', 'we', 'another', 'seeming', 'nevertheless', 'with', 'these', 'am', 'everyone', 'below', 'using', 'often', 'anywhere', 'elsewhere', 'much', 'have', 'make', 'around', 'than', 'do', 'somehow', 'at', 'except', 'regarding', 'used', 'rather', 'above', 'because', 'eight', 'twelve', 'forty', 'once', 'your', 'none', 'see', 'seemed', 'it', 'no', 'upon', 'if', 'too', 'be', 'toward', 'perhaps', 'least', 'i', 'amongst', 'empty', 'can', 'already', 'of', 'becomes', 'whole', 'that', 'then', 'whom', 'cannot', 'me', 'ourselves', \"'re\", 'sometimes', 'been', 'now', 'hundred', 'well', 'beforehand'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['myself'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a word to stopwords\n",
    "nlp.Defaults.stop_words.add('btw')\n",
    "nlp.Defaults.stop_words.remove('hers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matcher with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows us to set rules or regular expressions to match with a Doc object, and it returns a list containing the found matches\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = [{'LOWER': 'solarpower'}]\n",
    "pattern2 = [{'LOWER': 'solar'}, {'LOWER': 'power'}]\n",
    "pattern3 = [{'LOWER': 'solar'}, {'IS_PUNCT': True}, {'LOWER': 'power'}]\n",
    "matcher.add('SolarPower',[pattern1, pattern2, pattern3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 1, 3), (8656102463236116519, 10, 11), (8656102463236116519, 13, 16)]\n"
     ]
    }
   ],
   "source": [
    "# Applying Matcher to the doc object\n",
    "document = nlp(u'The Solar Power industry continues to grow as demand \\\n",
    "for solarpower increases. Solar-power cars are gaining popularity.')\n",
    "found_matches = matcher(document)\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8656102463236116519 SolarPower 1 3 is a\n",
      "8656102463236116519 SolarPower 10 11 to\n",
      "8656102463236116519 SolarPower 13 16 he ran today\n"
     ]
    }
   ],
   "source": [
    "# Finding out text for the matches\n",
    "for match_id, start, end in found_matches:\n",
    "    # get string representation\n",
    "    string_id = nlp.vocab.strings[match_id]\n",
    "    # get the matched span\n",
    "    span = doc[start:end]       \n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
