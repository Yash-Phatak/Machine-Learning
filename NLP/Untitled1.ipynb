{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b6d8150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "044964e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Yash\n",
      "[nltk_data]     Phatak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc6e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('bbc_text_cls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcc17d0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    labels\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "550ce43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#populating word2idx\n",
    "#converting docs into sequences of ints/indices\n",
    "idx = 0;\n",
    "word2idx = {}\n",
    "tokenized_docs = []\n",
    "for doc in data['text']:\n",
    "    words = word_tokenize(doc.lower())\n",
    "    doc_as_int = []\n",
    "    for word in words:\n",
    "        if word not in word2idx:\n",
    "            word2idx[word]= idx\n",
    "            idx+=1\n",
    "        doc_as_int.append(word2idx[word])\n",
    "    tokenized_docs.append(doc_as_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3106c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reverse mapping\n",
    "#for retrieving the data back especially useful in deep learning models\n",
    "#with this method we will swap the values and the indices present in the word2idx \n",
    "idx2word = {v:k for k,v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b88a5232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The final matrix is in form of NxV where N are number of docs and V is number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fc2ab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of documents \n",
    "N = len(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b42514fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of words \n",
    "V = len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bef7a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now design a term-frequency matrix\n",
    "tf = np.zeros((N,V)) #initializing a NxV matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12858b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enumerate at 0x1a3ac88f440>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enumerate(tokenized_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63a67f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#popualate tf\n",
    "for i,doc_as_int in enumerate(tokenized_docs):\n",
    "    for j in doc_as_int:\n",
    "        tf[i,j]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "767af620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute IDF\n",
    "document_freq = np.sum(tf>0,axis=0) #doc frequency (shape=(V,))\n",
    "document_freq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
